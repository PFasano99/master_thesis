#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile:
#1 transferring dockerfile: 1.39kB 0.1s done
#1 DONE 0.3s

#2 [internal] load .dockerignore
#2 transferring context: 2B 0.0s done
#2 DONE 0.5s

#3 [internal] load metadata for docker.io/pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime
#3 DONE 1.3s

#4 [ 1/13] FROM docker.io/pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime@sha256:fabb5a665a05b8ee0ac76f0d943acc40039e13536e11a44d3dc47625a266e759
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 9.05kB done
#5 DONE 0.1s

#6 [ 8/13] RUN pip install git+https://github.com/facebookresearch/segment-anything.git
#6 CACHED

#7 [ 7/13] RUN pip install git+https://github.com/gradslam/gradslam.git@conceptfusion
#7 CACHED

#8 [ 9/13] RUN pip install git+https://github.com/openai/CLIP.git
#8 CACHED

#9 [ 3/13] RUN apt-get update &&     apt-get install -y                 apt-utils                 python3                 python3-pip                 python3-dev                 git                 build-essential                 ffmpeg                 libsm6                 libxext6                 libblas-dev                 libatlas-base-dev                 && rm -rf /var/lib/apt/lists/*
#9 CACHED

#10 [ 5/13] COPY ./requirements.txt /extract_features/requirements.txt
#10 CACHED

#11 [10/13] RUN pip install open_clip_torch
#11 CACHED

#12 [ 4/13] RUN pip install setuptools --upgrade
#12 CACHED

#13 [11/13] RUN pip install --extra-index-url https://pypi.nvidia.com cuml-cu11==23.2.0
#13 CACHED

#14 [ 2/13] WORKDIR /workspace
#14 CACHED

#15 [ 6/13] RUN pip3 install -r /extract_features/requirements.txt
#15 CACHED

#16 [12/13] RUN pip install git+https://github.com/facebookresearch/dinov2
#16 CACHED

#17 [13/13] COPY ./feature_extraction.py /extract_features/feature_extraction.py
#17 DONE 0.3s

#18 exporting to image
#18 exporting layers
#18 exporting layers 0.1s done
#18 writing image sha256:ff506ac2fe44f5ca6ee0ecd42207b6f8dc2bb32a50ada4d9693b5235ba7641ca done
#18 naming to Paolo.Fasano/tesi_image:extract_features 0.1s done
#18 DONE 0.2s
/home/paolofasano/tesi_fasano/master_thesis
181
Initializing CLIP model: ViT-H-14 pre-trained on laion2b_s32b_b79k
open_clip_pytorch_model.bin:   0% 0.00/3.94G [00:00<?, ?B/s]open_clip_pytorch_model.bin:   0% 10.5M/3.94G [00:00<01:04, 60.9MB/s]open_clip_pytorch_model.bin:   1% 21.0M/3.94G [00:00<01:01, 63.7MB/s]open_clip_pytorch_model.bin:   1% 31.5M/3.94G [00:00<00:57, 67.7MB/s]open_clip_pytorch_model.bin:   1% 41.9M/3.94G [00:00<00:59, 66.1MB/s]open_clip_pytorch_model.bin:   1% 52.4M/3.94G [00:00<00:58, 66.1MB/s]open_clip_pytorch_model.bin:   2% 62.9M/3.94G [00:00<00:54, 70.6MB/s]open_clip_pytorch_model.bin:   2% 73.4M/3.94G [00:01<00:53, 71.8MB/s]open_clip_pytorch_model.bin:   2% 83.9M/3.94G [00:01<00:48, 79.7MB/s]open_clip_pytorch_model.bin:   3% 105M/3.94G [00:01<00:40, 94.1MB/s] open_clip_pytorch_model.bin:   3% 126M/3.94G [00:01<00:37, 102MB/s] open_clip_pytorch_model.bin:   4% 147M/3.94G [00:01<00:35, 107MB/s]open_clip_pytorch_model.bin:   4% 168M/3.94G [00:01<00:34, 110MB/s]open_clip_pytorch_model.bin:   5% 189M/3.94G [00:02<00:33, 111MB/s]open_clip_pytorch_model.bin:   5% 210M/3.94G [00:02<00:33, 113MB/s]open_clip_pytorch_model.bin:   6% 231M/3.94G [00:02<00:32, 114MB/s]open_clip_pytorch_model.bin:   6% 252M/3.94G [00:02<00:32, 115MB/s]open_clip_pytorch_model.bin:   7% 273M/3.94G [00:02<00:31, 116MB/s]open_clip_pytorch_model.bin:   7% 294M/3.94G [00:02<00:31, 116MB/s]open_clip_pytorch_model.bin:   8% 315M/3.94G [00:03<00:31, 117MB/s]open_clip_pytorch_model.bin:   9% 336M/3.94G [00:03<00:30, 117MB/s]open_clip_pytorch_model.bin:   9% 357M/3.94G [00:03<00:30, 117MB/s]open_clip_pytorch_model.bin:  10% 377M/3.94G [00:03<00:30, 117MB/s]open_clip_pytorch_model.bin:  10% 398M/3.94G [00:03<00:30, 117MB/s]open_clip_pytorch_model.bin:  11% 419M/3.94G [00:04<00:30, 117MB/s]open_clip_pytorch_model.bin:  11% 440M/3.94G [00:04<00:29, 117MB/s]open_clip_pytorch_model.bin:  12% 461M/3.94G [00:04<00:29, 117MB/s]open_clip_pytorch_model.bin:  12% 482M/3.94G [00:04<00:29, 117MB/s]open_clip_pytorch_model.bin:  13% 503M/3.94G [00:04<00:29, 117MB/s]open_clip_pytorch_model.bin:  13% 524M/3.94G [00:04<00:29, 117MB/s]open_clip_pytorch_model.bin:  14% 545M/3.94G [00:05<00:29, 115MB/s]open_clip_pytorch_model.bin:  14% 566M/3.94G [00:05<00:29, 116MB/s]open_clip_pytorch_model.bin:  15% 587M/3.94G [00:05<00:28, 117MB/s]open_clip_pytorch_model.bin:  15% 608M/3.94G [00:05<00:28, 117MB/s]open_clip_pytorch_model.bin:  16% 629M/3.94G [00:05<00:28, 117MB/s]open_clip_pytorch_model.bin:  16% 650M/3.94G [00:06<00:28, 117MB/s]open_clip_pytorch_model.bin:  17% 671M/3.94G [00:06<00:27, 117MB/s]open_clip_pytorch_model.bin:  18% 692M/3.94G [00:06<00:27, 117MB/s]open_clip_pytorch_model.bin:  18% 713M/3.94G [00:06<00:27, 117MB/s]open_clip_pytorch_model.bin:  19% 734M/3.94G [00:06<00:27, 117MB/s]open_clip_pytorch_model.bin:  19% 755M/3.94G [00:06<00:27, 117MB/s]open_clip_pytorch_model.bin:  20% 776M/3.94G [00:07<00:26, 117MB/s]open_clip_pytorch_model.bin:  20% 797M/3.94G [00:07<00:26, 117MB/s]open_clip_pytorch_model.bin:  21% 818M/3.94G [00:07<00:26, 117MB/s]open_clip_pytorch_model.bin:  21% 839M/3.94G [00:07<00:26, 117MB/s]open_clip_pytorch_model.bin:  22% 860M/3.94G [00:07<00:26, 117MB/s]open_clip_pytorch_model.bin:  22% 881M/3.94G [00:07<00:26, 118MB/s]open_clip_pytorch_model.bin:  23% 902M/3.94G [00:08<00:25, 118MB/s]open_clip_pytorch_model.bin:  23% 923M/3.94G [00:08<00:25, 118MB/s]open_clip_pytorch_model.bin:  24% 944M/3.94G [00:08<00:25, 117MB/s]open_clip_pytorch_model.bin:  24% 965M/3.94G [00:08<00:25, 117MB/s]open_clip_pytorch_model.bin:  25% 986M/3.94G [00:08<00:25, 117MB/s]open_clip_pytorch_model.bin:  26% 1.01G/3.94G [00:09<00:25, 117MB/s]open_clip_pytorch_model.bin:  26% 1.03G/3.94G [00:09<00:24, 117MB/s]open_clip_pytorch_model.bin:  27% 1.05G/3.94G [00:09<00:24, 117MB/s]open_clip_pytorch_model.bin:  27% 1.07G/3.94G [00:09<00:24, 117MB/s]open_clip_pytorch_model.bin:  28% 1.09G/3.94G [00:09<00:24, 117MB/s]open_clip_pytorch_model.bin:  28% 1.11G/3.94G [00:09<00:24, 117MB/s]open_clip_pytorch_model.bin:  29% 1.13G/3.94G [00:10<00:23, 117MB/s]open_clip_pytorch_model.bin:  29% 1.15G/3.94G [00:10<00:23, 117MB/s]open_clip_pytorch_model.bin:  30% 1.17G/3.94G [00:10<00:23, 117MB/s]open_clip_pytorch_model.bin:  30% 1.20G/3.94G [00:10<00:23, 117MB/s]open_clip_pytorch_model.bin:  31% 1.22G/3.94G [00:10<00:23, 117MB/s]open_clip_pytorch_model.bin:  31% 1.24G/3.94G [00:11<00:23, 117MB/s]open_clip_pytorch_model.bin:  32% 1.26G/3.94G [00:11<00:22, 117MB/s]open_clip_pytorch_model.bin:  32% 1.28G/3.94G [00:11<00:22, 117MB/s]open_clip_pytorch_model.bin:  33% 1.30G/3.94G [00:11<00:22, 117MB/s]open_clip_pytorch_model.bin:  33% 1.32G/3.94G [00:11<00:22, 117MB/s]open_clip_pytorch_model.bin:  34% 1.34G/3.94G [00:11<00:22, 117MB/s]open_clip_pytorch_model.bin:  35% 1.36G/3.94G [00:12<00:21, 117MB/s]open_clip_pytorch_model.bin:  35% 1.38G/3.94G [00:12<00:21, 117MB/s]open_clip_pytorch_model.bin:  36% 1.41G/3.94G [00:12<00:21, 117MB/s]open_clip_pytorch_model.bin:  36% 1.43G/3.94G [00:12<00:21, 117MB/s]open_clip_pytorch_model.bin:  37% 1.45G/3.94G [00:12<00:21, 117MB/s]open_clip_pytorch_model.bin:  37% 1.47G/3.94G [00:12<00:21, 116MB/s]open_clip_pytorch_model.bin:  38% 1.49G/3.94G [00:13<00:21, 116MB/s]open_clip_pytorch_model.bin:  38% 1.51G/3.94G [00:13<00:21, 114MB/s]open_clip_pytorch_model.bin:  39% 1.53G/3.94G [00:13<00:21, 115MB/s]open_clip_pytorch_model.bin:  39% 1.55G/3.94G [00:13<00:20, 116MB/s]open_clip_pytorch_model.bin:  40% 1.57G/3.94G [00:13<00:20, 116MB/s]open_clip_pytorch_model.bin:  40% 1.59G/3.94G [00:14<00:20, 117MB/s]open_clip_pytorch_model.bin:  41% 1.61G/3.94G [00:14<00:19, 117MB/s]open_clip_pytorch_model.bin:  41% 1.64G/3.94G [00:14<00:19, 117MB/s]open_clip_pytorch_model.bin:  42% 1.66G/3.94G [00:14<00:19, 117MB/s]open_clip_pytorch_model.bin:  43% 1.68G/3.94G [00:14<00:19, 117MB/s]open_clip_pytorch_model.bin:  43% 1.70G/3.94G [00:14<00:19, 117MB/s]open_clip_pytorch_model.bin:  44% 1.72G/3.94G [00:15<00:18, 117MB/s]open_clip_pytorch_model.bin:  44% 1.74G/3.94G [00:15<00:18, 117MB/s]open_clip_pytorch_model.bin:  45% 1.76G/3.94G [00:15<00:18, 117MB/s]open_clip_pytorch_model.bin:  45% 1.78G/3.94G [00:15<00:18, 118MB/s]open_clip_pytorch_model.bin:  46% 1.80G/3.94G [00:15<00:18, 117MB/s]open_clip_pytorch_model.bin:  46% 1.82G/3.94G [00:16<00:18, 117MB/s]open_clip_pytorch_model.bin:  47% 1.85G/3.94G [00:16<00:17, 117MB/s]open_clip_pytorch_model.bin:  47% 1.87G/3.94G [00:16<00:17, 117MB/s]open_clip_pytorch_model.bin:  48% 1.89G/3.94G [00:16<00:17, 117MB/s]open_clip_pytorch_model.bin:  48% 1.91G/3.94G [00:16<00:17, 117MB/s]open_clip_pytorch_model.bin:  49% 1.93G/3.94G [00:16<00:17, 117MB/s]open_clip_pytorch_model.bin:  49% 1.95G/3.94G [00:17<00:16, 117MB/s]open_clip_pytorch_model.bin:  50% 1.97G/3.94G [00:17<00:16, 117MB/s]open_clip_pytorch_model.bin:  51% 1.99G/3.94G [00:17<00:16, 117MB/s]open_clip_pytorch_model.bin:  51% 2.01G/3.94G [00:17<00:16, 117MB/s]open_clip_pytorch_model.bin:  52% 2.03G/3.94G [00:17<00:16, 117MB/s]open_clip_pytorch_model.bin:  52% 2.06G/3.94G [00:18<00:16, 117MB/s]open_clip_pytorch_model.bin:  53% 2.08G/3.94G [00:18<00:19, 97.5MB/s]open_clip_pytorch_model.bin:  53% 2.10G/3.94G [00:18<00:17, 103MB/s] open_clip_pytorch_model.bin:  54% 2.12G/3.94G [00:18<00:22, 80.5MB/s]open_clip_pytorch_model.bin:  54% 2.14G/3.94G [00:19<00:20, 88.9MB/s]open_clip_pytorch_model.bin:  55% 2.16G/3.94G [00:19<00:18, 95.9MB/s]open_clip_pytorch_model.bin:  55% 2.18G/3.94G [00:19<00:17, 101MB/s] open_clip_pytorch_model.bin:  56% 2.20G/3.94G [00:19<00:16, 105MB/s]open_clip_pytorch_model.bin:  56% 2.22G/3.94G [00:19<00:15, 109MB/s]open_clip_pytorch_model.bin:  57% 2.24G/3.94G [00:19<00:15, 111MB/s]open_clip_pytorch_model.bin:  57% 2.26G/3.94G [00:20<00:15, 112MB/s]open_clip_pytorch_model.bin:  58% 2.29G/3.94G [00:20<00:14, 115MB/s]open_clip_pytorch_model.bin:  58% 2.31G/3.94G [00:20<00:14, 116MB/s]open_clip_pytorch_model.bin:  59% 2.33G/3.94G [00:20<00:13, 116MB/s]open_clip_pytorch_model.bin:  60% 2.35G/3.94G [00:20<00:13, 115MB/s]open_clip_pytorch_model.bin:  60% 2.37G/3.94G [00:21<00:13, 117MB/s]open_clip_pytorch_model.bin:  61% 2.39G/3.94G [00:21<00:13, 117MB/s]open_clip_pytorch_model.bin:  61% 2.41G/3.94G [00:21<00:13, 117MB/s]open_clip_pytorch_model.bin:  62% 2.43G/3.94G [00:21<00:13, 116MB/s]open_clip_pytorch_model.bin:  62% 2.45G/3.94G [00:21<00:12, 118MB/s]open_clip_pytorch_model.bin:  63% 2.47G/3.94G [00:21<00:12, 118MB/s]open_clip_pytorch_model.bin:  63% 2.50G/3.94G [00:22<00:12, 118MB/s]open_clip_pytorch_model.bin:  64% 2.52G/3.94G [00:22<00:12, 117MB/s]open_clip_pytorch_model.bin:  64% 2.54G/3.94G [00:22<00:12, 117MB/s]open_clip_pytorch_model.bin:  65% 2.56G/3.94G [00:22<00:11, 116MB/s]open_clip_pytorch_model.bin:  65% 2.58G/3.94G [00:22<00:11, 116MB/s]open_clip_pytorch_model.bin:  66% 2.60G/3.94G [00:22<00:11, 116MB/s]open_clip_pytorch_model.bin:  66% 2.62G/3.94G [00:23<00:11, 116MB/s]open_clip_pytorch_model.bin:  67% 2.64G/3.94G [00:23<00:11, 116MB/s]open_clip_pytorch_model.bin:  68% 2.66G/3.94G [00:23<00:11, 116MB/s]open_clip_pytorch_model.bin:  68% 2.68G/3.94G [00:23<00:10, 116MB/s]open_clip_pytorch_model.bin:  69% 2.71G/3.94G [00:23<00:10, 116MB/s]open_clip_pytorch_model.bin:  69% 2.73G/3.94G [00:24<00:10, 116MB/s]open_clip_pytorch_model.bin:  70% 2.75G/3.94G [00:24<00:10, 116MB/s]open_clip_pytorch_model.bin:  70% 2.77G/3.94G [00:24<00:10, 116MB/s]open_clip_pytorch_model.bin:  71% 2.79G/3.94G [00:24<00:09, 116MB/s]open_clip_pytorch_model.bin:  71% 2.81G/3.94G [00:24<00:09, 116MB/s]open_clip_pytorch_model.bin:  72% 2.83G/3.94G [00:24<00:09, 116MB/s]open_clip_pytorch_model.bin:  72% 2.85G/3.94G [00:25<00:09, 116MB/s]open_clip_pytorch_model.bin:  73% 2.87G/3.94G [00:25<00:09, 116MB/s]open_clip_pytorch_model.bin:  73% 2.89G/3.94G [00:25<00:09, 116MB/s]open_clip_pytorch_model.bin:  74% 2.92G/3.94G [00:25<00:08, 116MB/s]open_clip_pytorch_model.bin:  74% 2.94G/3.94G [00:25<00:08, 116MB/s]open_clip_pytorch_model.bin:  75% 2.96G/3.94G [00:26<00:08, 116MB/s]open_clip_pytorch_model.bin:  75% 2.98G/3.94G [00:26<00:08, 116MB/s]open_clip_pytorch_model.bin:  76% 3.00G/3.94G [00:26<00:08, 116MB/s]open_clip_pytorch_model.bin:  77% 3.02G/3.94G [00:26<00:07, 116MB/s]open_clip_pytorch_model.bin:  77% 3.04G/3.94G [00:26<00:07, 116MB/s]open_clip_pytorch_model.bin:  78% 3.06G/3.94G [00:26<00:07, 116MB/s]open_clip_pytorch_model.bin:  78% 3.08G/3.94G [00:27<00:07, 116MB/s]open_clip_pytorch_model.bin:  79% 3.10G/3.94G [00:27<00:07, 117MB/s]open_clip_pytorch_model.bin:  79% 3.12G/3.94G [00:27<00:07, 117MB/s]open_clip_pytorch_model.bin:  80% 3.15G/3.94G [00:27<00:06, 116MB/s]open_clip_pytorch_model.bin:  80% 3.17G/3.94G [00:27<00:06, 118MB/s]open_clip_pytorch_model.bin:  81% 3.19G/3.94G [00:28<00:06, 118MB/s]open_clip_pytorch_model.bin:  81% 3.21G/3.94G [00:28<00:06, 118MB/s]open_clip_pytorch_model.bin:  82% 3.23G/3.94G [00:28<00:06, 117MB/s]open_clip_pytorch_model.bin:  82% 3.25G/3.94G [00:28<00:05, 118MB/s]open_clip_pytorch_model.bin:  83% 3.27G/3.94G [00:28<00:05, 117MB/s]open_clip_pytorch_model.bin:  83% 3.29G/3.94G [00:28<00:05, 117MB/s]open_clip_pytorch_model.bin:  84% 3.31G/3.94G [00:29<00:05, 117MB/s]open_clip_pytorch_model.bin:  85% 3.33G/3.94G [00:29<00:05, 117MB/s]open_clip_pytorch_model.bin:  85% 3.36G/3.94G [00:29<00:05, 117MB/s]open_clip_pytorch_model.bin:  86% 3.38G/3.94G [00:29<00:04, 117MB/s]open_clip_pytorch_model.bin:  86% 3.40G/3.94G [00:29<00:04, 117MB/s]open_clip_pytorch_model.bin:  87% 3.42G/3.94G [00:30<00:04, 117MB/s]open_clip_pytorch_model.bin:  87% 3.44G/3.94G [00:30<00:04, 117MB/s]open_clip_pytorch_model.bin:  88% 3.46G/3.94G [00:30<00:04, 117MB/s]open_clip_pytorch_model.bin:  88% 3.48G/3.94G [00:30<00:03, 117MB/s]open_clip_pytorch_model.bin:  89% 3.50G/3.94G [00:30<00:03, 117MB/s]open_clip_pytorch_model.bin:  89% 3.52G/3.94G [00:30<00:03, 117MB/s]open_clip_pytorch_model.bin:  90% 3.54G/3.94G [00:31<00:03, 116MB/s]open_clip_pytorch_model.bin:  90% 3.57G/3.94G [00:31<00:03, 117MB/s]open_clip_pytorch_model.bin:  91% 3.59G/3.94G [00:31<00:03, 118MB/s]open_clip_pytorch_model.bin:  91% 3.61G/3.94G [00:31<00:02, 118MB/s]open_clip_pytorch_model.bin:  92% 3.63G/3.94G [00:31<00:02, 118MB/s]open_clip_pytorch_model.bin:  93% 3.65G/3.94G [00:31<00:02, 118MB/s]open_clip_pytorch_model.bin:  93% 3.67G/3.94G [00:32<00:02, 118MB/s]open_clip_pytorch_model.bin:  94% 3.69G/3.94G [00:32<00:02, 118MB/s]open_clip_pytorch_model.bin:  94% 3.71G/3.94G [00:32<00:01, 118MB/s]open_clip_pytorch_model.bin:  95% 3.73G/3.94G [00:32<00:01, 117MB/s]open_clip_pytorch_model.bin:  95% 3.75G/3.94G [00:32<00:01, 117MB/s]open_clip_pytorch_model.bin:  96% 3.77G/3.94G [00:33<00:01, 117MB/s]open_clip_pytorch_model.bin:  96% 3.80G/3.94G [00:33<00:01, 116MB/s]open_clip_pytorch_model.bin:  97% 3.82G/3.94G [00:33<00:01, 117MB/s]open_clip_pytorch_model.bin:  97% 3.84G/3.94G [00:33<00:00, 117MB/s]open_clip_pytorch_model.bin:  98% 3.86G/3.94G [00:33<00:00, 117MB/s]open_clip_pytorch_model.bin:  98% 3.88G/3.94G [00:33<00:00, 117MB/s]open_clip_pytorch_model.bin:  99% 3.90G/3.94G [00:34<00:00, 86.6MB/s]open_clip_pytorch_model.bin:  99% 3.92G/3.94G [00:34<00:00, 93.2MB/s]open_clip_pytorch_model.bin: 100% 3.94G/3.94G [00:34<00:00, 99.4MB/s]open_clip_pytorch_model.bin: 100% 3.94G/3.94G [00:34<00:00, 114MB/s] 
/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
pkl file found:  181
Computing pixel-aligned features...
  0% 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
saving at:  ./resources/dataset/cnr_c60/openClip-saved-feat/133468485619166969.bin
100% 1/1 [00:32<00:00, 32.95s/it]100% 1/1 [00:32<00:00, 32.95s/it]
